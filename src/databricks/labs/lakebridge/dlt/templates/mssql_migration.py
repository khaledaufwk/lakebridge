# Databricks notebook source
# MAGIC %md
# MAGIC # MSSQL to Databricks DLT Migration Pipeline
# MAGIC 
# MAGIC This pipeline migrates data from Microsoft SQL Server to Databricks:
# MAGIC - Initial full load with watermark tracking
# MAGIC - Incremental updates using change tracking
# MAGIC - Data quality validation
# MAGIC 
# MAGIC Generated by Lakebridge Migration Tool

# COMMAND ----------

import dlt
from pyspark.sql import functions as F

# Configuration (update these values)
MSSQL_HOST = spark.conf.get("pipeline.mssql.host", "your-server.database.windows.net")
MSSQL_DATABASE = spark.conf.get("pipeline.mssql.database", "your_database")
MSSQL_USER = spark.conf.get("pipeline.mssql.user", "")
MSSQL_PASSWORD = dbutils.secrets.get(scope="mssql", key="password")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Helper Functions

# COMMAND ----------

def read_mssql_table(table_name: str, query: str = None):
    """Read a table from MSSQL."""
    jdbc_url = f"jdbc:sqlserver://{MSSQL_HOST}:1433;database={MSSQL_DATABASE};encrypt=true;trustServerCertificate=false"
    
    reader = (
        spark.read
        .format("jdbc")
        .option("url", jdbc_url)
        .option("user", MSSQL_USER)
        .option("password", MSSQL_PASSWORD)
        .option("driver", "com.microsoft.sqlserver.jdbc.SQLServerDriver")
    )
    
    if query:
        reader = reader.option("query", query)
    else:
        reader = reader.option("dbtable", table_name)
    
    return reader.load()

# COMMAND ----------

# MAGIC %md
# MAGIC ## Source Tables

# COMMAND ----------

@dlt.table(
    name="bronze_customers",
    comment="Raw customers from MSSQL",
    table_properties={"quality": "bronze"}
)
def bronze_customers():
    """Load customers table from MSSQL."""
    return read_mssql_table("dbo.Customers")

# COMMAND ----------

@dlt.table(
    name="bronze_orders",
    comment="Raw orders from MSSQL",
    table_properties={"quality": "bronze"}
)
def bronze_orders():
    """Load orders table from MSSQL."""
    return read_mssql_table("dbo.Orders")

# COMMAND ----------

@dlt.table(
    name="bronze_order_items",
    comment="Raw order items from MSSQL",
    table_properties={"quality": "bronze"}
)
def bronze_order_items():
    """Load order items table from MSSQL."""
    return read_mssql_table("dbo.OrderItems")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Silver Layer - Cleaned and Joined

# COMMAND ----------

@dlt.expect_or_drop("valid_customer_id", "customer_id IS NOT NULL")
@dlt.expect("valid_email", "email IS NOT NULL AND email LIKE '%@%'")
@dlt.table(
    name="silver_customers",
    comment="Cleaned customer data",
    table_properties={"quality": "silver"}
)
def silver_customers():
    """Clean and validate customer data."""
    return (
        dlt.read("bronze_customers")
        .withColumn("email", F.lower(F.trim(F.col("email"))))
        .withColumn("full_name", F.concat_ws(" ", F.col("first_name"), F.col("last_name")))
        .withColumn("processed_at", F.current_timestamp())
        .dropDuplicates(["customer_id"])
    )

# COMMAND ----------

@dlt.expect_or_drop("valid_order_id", "order_id IS NOT NULL")
@dlt.expect_or_drop("valid_order_customer", "customer_id IS NOT NULL")
@dlt.table(
    name="silver_orders",
    comment="Cleaned order data with customer info",
    table_properties={"quality": "silver"}
)
def silver_orders():
    """Clean orders and join with customers."""
    orders = dlt.read("bronze_orders")
    customers = dlt.read("silver_customers")
    
    return (
        orders
        .join(customers.select("customer_id", "full_name", "email"), "customer_id", "left")
        .withColumn("order_date", F.to_date("order_date"))
        .withColumn("processed_at", F.current_timestamp())
    )

# COMMAND ----------

# MAGIC %md
# MAGIC ## Gold Layer - Business Aggregates

# COMMAND ----------

@dlt.table(
    name="gold_customer_summary",
    comment="Customer order summary",
    table_properties={"quality": "gold"}
)
def gold_customer_summary():
    """Aggregate customer order metrics."""
    orders = dlt.read("silver_orders")
    items = dlt.read("bronze_order_items")
    
    order_totals = (
        items
        .groupBy("order_id")
        .agg(F.sum(F.col("quantity") * F.col("unit_price")).alias("order_total"))
    )
    
    return (
        orders
        .join(order_totals, "order_id", "left")
        .groupBy("customer_id", "full_name", "email")
        .agg(
            F.count("order_id").alias("total_orders"),
            F.sum("order_total").alias("total_revenue"),
            F.avg("order_total").alias("avg_order_value"),
            F.min("order_date").alias("first_order_date"),
            F.max("order_date").alias("last_order_date"),
        )
    )

# COMMAND ----------

@dlt.table(
    name="gold_daily_sales",
    comment="Daily sales summary",
    table_properties={"quality": "gold"}
)
def gold_daily_sales():
    """Daily sales aggregation."""
    orders = dlt.read("silver_orders")
    items = dlt.read("bronze_order_items")
    
    order_totals = (
        items
        .groupBy("order_id")
        .agg(F.sum(F.col("quantity") * F.col("unit_price")).alias("order_total"))
    )
    
    return (
        orders
        .join(order_totals, "order_id", "left")
        .groupBy("order_date")
        .agg(
            F.count("order_id").alias("total_orders"),
            F.sum("order_total").alias("total_revenue"),
            F.countDistinct("customer_id").alias("unique_customers"),
        )
        .orderBy("order_date")
    )
